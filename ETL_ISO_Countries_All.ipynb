{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests pandas beautifulsoup4 pycountry"
      ],
      "metadata": {
        "id": "qO1nTCJh4YkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -N https://download.geonames.org/export/dump/countryInfo.txt\n",
        "!wget -N https://download.geonames.org/export/dump/admin1CodesASCII.txt\n",
        "!wget -N https://download.geonames.org/export/dump/allCountries.zip\n",
        "!unzip -o allCountries.zip"
      ],
      "metadata": {
        "id": "WW19sHZY4dHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import pycountry\n",
        "from datetime import datetime\n",
        "import os\n",
        "import json"
      ],
      "metadata": {
        "id": "f1nl_JZp4ic9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONTINENT_MAP = {\n",
        "    'AS': 'Asia',\n",
        "    'AF': 'Africa',\n",
        "    'NA': 'North America',\n",
        "    'SA': 'South America',\n",
        "    'EU': 'Europe',\n",
        "    'OC': 'Oceania',\n",
        "    'AN': 'Antarctica'\n",
        "}\n",
        "\n",
        "BASE_PATH = '/content/geodata/'\n",
        "os.makedirs(BASE_PATH, exist_ok=True)"
      ],
      "metadata": {
        "id": "OlvOCnZr4mRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_continent_data():\n",
        "  \"\"\"\n",
        "    Obtiene y procesa datos básicos de todos los continentes\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        continents_data: DataFrame con información de los Continentes\n",
        "  \"\"\"\n",
        "  print(\"Obteniendo datos de los continentes...\")\n",
        "  continents_data = []\n",
        "  for idx, (code, name) in enumerate(CONTINENT_MAP.items(), start=1):\n",
        "      continents_data.append({\n",
        "          'id': idx,\n",
        "          'code': code,\n",
        "          'name': name,\n",
        "          'is_active': 1,\n",
        "          'created_at': datetime.now(),\n",
        "          'updated_at': datetime.now()\n",
        "      })\n",
        "  return pd.DataFrame(continents_data)"
      ],
      "metadata": {
        "id": "69bxsyt09KPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_countries_data():\n",
        "  \"\"\"\n",
        "    Obtiene y procesa datos básicos de todos los países\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        countries_data: DataFrame con información de los países\n",
        "  \"\"\"\n",
        "  url = \"https://restcountries.com/v3.1/all\"\n",
        "  try:\n",
        "      print(\"Obteniendo datos de países...\")\n",
        "      response = requests.get(url, timeout=20)\n",
        "      response.raise_for_status()\n",
        "  except requests.exceptions.Timeout:\n",
        "      print(\"La solicitud excedió el tiempo de espera.\")\n",
        "      return pd.DataFrame()\n",
        "  except requests.exceptions.RequestException as e:\n",
        "      print(f\"Error al hacer la solicitud: {e}\")\n",
        "      return pd.DataFrame()\n",
        "\n",
        "  data = response.json()\n",
        "\n",
        "  country_data = []\n",
        "  for country in data:\n",
        "      try:\n",
        "          region = country.get('region', '')\n",
        "          continent_map = {\n",
        "              'Asia': 'AS',\n",
        "              'Africa': 'AF',\n",
        "              'Americas': 'NA',\n",
        "              'Europe': 'EU',\n",
        "              'Oceania': 'OC',\n",
        "              'Antarctic': 'AN'\n",
        "          }\n",
        "          continent_code = continent_map.get(region, 'OC')\n",
        "\n",
        "          if region == 'Americas':\n",
        "              subregion = country.get('subregion', '')\n",
        "              if subregion and ('South' in subregion):\n",
        "                  continent_code = 'SA'\n",
        "              else:\n",
        "                  continent_code = 'NA'\n",
        "\n",
        "          if not country.get('cca2'):\n",
        "              continue\n",
        "\n",
        "          country_dict = {\n",
        "              'alpha_2_code': country.get('cca2', ''),\n",
        "              'alpha_3_code': country.get('cca3', ''),\n",
        "              'numeric_code': country.get('ccn3', '000') if country.get('ccn3') else '000',\n",
        "              'official_name': country.get('name', {}).get('official', ''),\n",
        "              'common_name': country.get('name', {}).get('common', ''),\n",
        "              'english_name': country.get('name', {}).get('official', ''),\n",
        "              'continent_code': continent_code,\n",
        "              'is_active': 1,\n",
        "              'created_at': datetime.now(),\n",
        "              'updated_at': datetime.now(),\n",
        "              'capital': country.get('capital', []),\n",
        "              'timezones': country.get('timezones', []),\n",
        "              'callingCode': country.get('idd', {}).get('root', '') + (country.get('idd', {}).get('suffixes', [''])[0] if country.get('idd', {}).get('suffixes') else '')\n",
        "          }\n",
        "\n",
        "          if len(country_dict['alpha_2_code']) == 2:\n",
        "              country_data.append(country_dict)\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error procesando país: {str(e)}\")\n",
        "\n",
        "  return pd.DataFrame(country_data)"
      ],
      "metadata": {
        "id": "yY4AlGunBzLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_countries_info_data(df_countries):\n",
        "  \"\"\"\n",
        "    Obtiene y procesa datos básicos de todos los países\n",
        "    Args:\n",
        "        df_countries: DataFrame con la información de países\n",
        "    Returns:\n",
        "        countries_info_data: DataFrame con información de los países\n",
        "  \"\"\"\n",
        "  print(\"Obteniendo información adicional de países...\")\n",
        "  country_info_data = []\n",
        "\n",
        "  if 'continent_code' not in df_countries.columns:\n",
        "      print(\"Advertencia: 'continent_code' no está en df_countries, agregando columna predeterminada\")\n",
        "      df_countries['continent_code'] = 'OC'\n",
        "\n",
        "  for index, row in df_countries.iterrows():\n",
        "      try:\n",
        "          info_dict = {\n",
        "              'country_alpha2': row['alpha_2_code'],\n",
        "              'capital': ', '.join(row.get('capital', []) if isinstance(row.get('capital'), list) else []),\n",
        "              'flag_png': f\"https://flagcdn.com/w320/{row['alpha_2_code'].lower()}.png\",\n",
        "              'flag_svg': f\"https://flagcdn.com/{row['alpha_2_code'].lower()}.svg\",\n",
        "              'calling_code': f\"+{row.get('callingCode', '')}\",\n",
        "              'timezones': json.dumps(row.get('timezones', [])),\n",
        "              'continent_code': row['continent_code'],\n",
        "              'is_active': True,\n",
        "              'created_at': datetime.now(),\n",
        "              'updated_at': datetime.now()\n",
        "          }\n",
        "          country_info_data.append(info_dict)\n",
        "      except Exception as e:\n",
        "          print(f\"Error en info país {row['alpha_2_code']}: {str(e)}\")\n",
        "\n",
        "  result_df = pd.DataFrame(country_info_data)\n",
        "  if 'continent_code' not in result_df.columns:\n",
        "      print(\"Error: 'continent_code' no está en el DataFrame resultante\")\n",
        "      result_df['continent_code'] = 'OC'\n",
        "\n",
        "  return result_df"
      ],
      "metadata": {
        "id": "xtggbSKgDdi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_geonames_cities():\n",
        "  \"\"\"\n",
        "    Obtiene y procesa datos básicos de todas las ciudades\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        cities_data: DataFrame con información de las ciudades\n",
        "  \"\"\"\n",
        "  print(\"Procesando ciudades...\")\n",
        "  columns = [\n",
        "      'geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude',\n",
        "      'feature_class', 'feature_code', 'country_code', 'cc2', 'admin1_code',\n",
        "      'admin2_code', 'admin3_code', 'admin4_code', 'population', 'elevation',\n",
        "      'dem', 'timezone', 'modification_date'\n",
        "  ]\n",
        "\n",
        "  chunks = []\n",
        "  for chunk in pd.read_csv('allCountries.txt', sep='\\t', names=columns, chunksize=100000, dtype=str):\n",
        "      chunk = chunk[chunk['feature_class'] == 'P']\n",
        "      chunks.append(chunk)\n",
        "\n",
        "  df = pd.concat(chunks)\n",
        "\n",
        "  df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')\n",
        "  df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')\n",
        "  df['population'] = pd.to_numeric(df['population'], errors='coerce').fillna(0)\n",
        "  df['elevation'] = pd.to_numeric(df['elevation'], errors='coerce').fillna(0)\n",
        "\n",
        "  df['is_capital'] = df['feature_code'].isin(['PPLC', 'PPLA'])\n",
        "  df['is_state_capital'] = df['feature_code'].isin(['PPLA', 'PPLA2', 'PPLA3', 'PPLA4'])\n",
        "\n",
        "  return df[[\n",
        "      'geonameid', 'name', 'latitude', 'longitude',\n",
        "      'country_code', 'admin1_code', 'population',\n",
        "      'is_capital', 'is_state_capital', 'timezone'\n",
        "  ]]"
      ],
      "metadata": {
        "id": "R2xS8eFYD4jb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_regions():\n",
        "  \"\"\"\n",
        "    Obtiene y procesa datos básicos de todas las regiones\n",
        "    Args:\n",
        "        None\n",
        "    Returns:\n",
        "        regions_data: DataFrame con información de las regiones\n",
        "  \"\"\"\n",
        "  print(\"Procesando regiones...\")\n",
        "  df = pd.read_csv('admin1CodesASCII.txt', sep='\\t',\n",
        "                    names=['code', 'name', 'name_ascii', 'geonameid'])\n",
        "\n",
        "  df[['country_code', 'region_code']] = df['code'].str.split('.', expand=True)\n",
        "  df['admin_type'] = 'REGION'\n",
        "\n",
        "  return df[[\n",
        "      'country_code', 'region_code', 'name',\n",
        "      'admin_type', 'geonameid'\n",
        "  ]]"
      ],
      "metadata": {
        "id": "nz-kvtrCEHxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enrich_with_continent(data_df, country_df):\n",
        "  \"\"\"\n",
        "    Agrega información de continente a los datos\n",
        "    Args:\n",
        "        data_df: DataFrame con información de las regiones\n",
        "        country_df: DataFrame con información de los países\n",
        "    Returns:\n",
        "        merged: DataFrame con información de las regiones y países\n",
        "  \"\"\"\n",
        "  print(\"Agregando información de continente...\")\n",
        "\n",
        "  if 'continent_code' not in country_df.columns:\n",
        "      print(\"Advertencia: 'continent_code' no encontrada en country_df, agregando columna predeterminada\")\n",
        "      country_df['continent_code'] = 'OC'\n",
        "\n",
        "  if 'alpha_2_code' not in country_df.columns:\n",
        "      print(\"Error: 'alpha_2_code' no encontrada en country_df\")\n",
        "      if 'cca2' in country_df.columns:\n",
        "          country_df['alpha_2_code'] = country_df['cca2']\n",
        "      else:\n",
        "          return data_df\n",
        "\n",
        "  if 'country_code' not in data_df.columns:\n",
        "      print(\"Error: 'country_code' no encontrada en data_df\")\n",
        "      return data_df\n",
        "\n",
        "  try:\n",
        "      merged = data_df.merge(\n",
        "          country_df[['alpha_2_code', 'continent_code']],\n",
        "          left_on='country_code',\n",
        "          right_on='alpha_2_code',\n",
        "          how='left'\n",
        "      )\n",
        "      merged = merged.drop(columns=['alpha_2_code'])\n",
        "      merged['continent_code'] = merged['continent_code'].fillna('OC')\n",
        "      return merged\n",
        "  except Exception as e:\n",
        "      print(f\"Error en la fusión: {e}\")\n",
        "      data_df['continent_code'] = 'OC'\n",
        "  return data_df"
      ],
      "metadata": {
        "id": "Dm0_TYTmEMeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_save(data_df, base_name):\n",
        "    \"\"\"\n",
        "    Divide y guarda los datos por continente\n",
        "    Args:\n",
        "        data_df: DataFrame con información de los datos\n",
        "        base_name: Nombre base de los archivos\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    print(f\"Dividiendo y guardando {base_name}...\")\n",
        "\n",
        "    if 'continent_code' not in data_df.columns:\n",
        "        print(f\"Advertencia: 'continent_code' no encontrada en {base_name}_df, agregando columna predeterminada\")\n",
        "        data_df['continent_code'] = 'OC'\n",
        "\n",
        "    data_df.to_csv(f\"{BASE_PATH}all_{base_name}.csv\", index=False, encoding='utf-8-sig')\n",
        "\n",
        "    for continent_code in CONTINENT_MAP.keys():\n",
        "        filtered = data_df[data_df['continent_code'] == continent_code]\n",
        "        if not filtered.empty:\n",
        "            filename = f\"{BASE_PATH}{CONTINENT_MAP[continent_code].lower()}_{base_name}.csv\"\n",
        "            filtered.to_csv(filename, index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "_MqJj_hEEQMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Verificar las dependencias\n",
        "    try:\n",
        "        import requests\n",
        "        import pandas as pd\n",
        "        import pycountry\n",
        "        print(\"Todas las bibliotecas necesarias están disponibles\")\n",
        "    except ImportError as e:\n",
        "        print(f\"Error importando bibliotecas: {e}\")\n",
        "        return\n",
        "\n",
        "    print(\"Iniciando ETL de datos geográficos...\")\n",
        "\n",
        "    # Paso 1: Procesar continentes (ahora se asigna un ID numérico)\n",
        "    try:\n",
        "        continents_df = get_continent_data()\n",
        "        continents_df.to_csv(f\"{BASE_PATH}continents.csv\", index=False)\n",
        "        print(\"Datos de continentes procesados\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando continentes: {e}\")\n",
        "        return\n",
        "\n",
        "    # Paso 2: Procesar países\n",
        "    try:\n",
        "        countries_df = get_countries_data()\n",
        "        if countries_df.empty:\n",
        "            print(\"No se obtuvieron datos de países\")\n",
        "            return\n",
        "\n",
        "        print(f\"Se obtuvieron datos de {len(countries_df)} países\")\n",
        "\n",
        "        if 'continent_code' not in countries_df.columns:\n",
        "            print(\"Error: 'continent_code' no está en countries_df\")\n",
        "            countries_df['continent_code'] = 'OC'\n",
        "\n",
        "        countries_df = countries_df.merge(\n",
        "            continents_df[['id', 'code']],\n",
        "            left_on='continent_code',\n",
        "            right_on='code',\n",
        "            how='left'\n",
        "        )\n",
        "        countries_df.rename(columns={'id': 'continent_id'}, inplace=True)\n",
        "        countries_df.drop(columns=['code'], inplace=True)\n",
        "\n",
        "        try:\n",
        "            split_and_save(countries_df, 'countries')\n",
        "            print(\"Países guardados por continente\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error guardando países: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error general procesando países: {e}\")\n",
        "        return\n",
        "\n",
        "    # Paso 3: Información adicional de países\n",
        "    try:\n",
        "        countries_info_df = get_countries_info_data(countries_df)\n",
        "        if not countries_info_df.empty:\n",
        "            split_and_save(countries_info_df, 'country_info')\n",
        "            print(\"Información adicional de países procesada\")\n",
        "        else:\n",
        "            print(\"No se obtuvo información adicional de países\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando información adicional: {e}\")\n",
        "\n",
        "    # Paso 4: Procesar regiones\n",
        "    try:\n",
        "        regions_df = process_regions()\n",
        "        regions_df = enrich_with_continent(regions_df, countries_df)\n",
        "        split_and_save(regions_df, 'regions')\n",
        "        print(\"Regiones procesadas\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando regiones: {e}\")\n",
        "\n",
        "    # Paso 5: Procesar ciudades\n",
        "    try:\n",
        "        cities_df = process_geonames_cities()\n",
        "        cities_df = enrich_with_continent(cities_df, countries_df)\n",
        "        split_and_save(cities_df, 'cities')\n",
        "        print(\"Ciudades procesadas\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando ciudades: {e}\")\n",
        "\n",
        "    # Paso 6: Ajustes finales en DataFrames para importación\n",
        "    try:\n",
        "        print(\"Realizando cambios finales...\")\n",
        "        df = pd.read_csv(f\"{BASE_PATH}all_countries.csv\", low_memory=False)\n",
        "        df_countries_main = df[['alpha_2_code', 'alpha_3_code', 'numeric_code',\n",
        "                                  'official_name', 'common_name', 'english_name',\n",
        "                                  'continent_id', 'is_active', 'created_at', 'updated_at']]\n",
        "        df_countries_main.to_csv(f\"{BASE_PATH}countries.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "        df_info = df[['alpha_2_code', 'capital', 'timezones', 'callingCode']].copy()\n",
        "        df_info.rename(columns={'callingCode': 'calling_code', 'alpha_2_code': 'country_code'}, inplace=True)\n",
        "        def fix_timezones(val):\n",
        "            try:\n",
        "                return json.loads(val) if isinstance(val, str) else val\n",
        "            except Exception:\n",
        "                return []\n",
        "        df_info['timezones'] = df_info['timezones'].apply(fix_timezones)\n",
        "        df_info.to_csv(f\"{BASE_PATH}country_info.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "        df_states = pd.read_csv(f\"{BASE_PATH}all_regions.csv\", low_memory=False)\n",
        "        df_states_processed = df_states[['country_code', 'region_code', 'name', 'admin_type']].copy()\n",
        "        df_states_processed.rename(columns={'region_code': 'code', 'name': 'official_name'}, inplace=True)\n",
        "        df_states_processed.to_csv(f\"{BASE_PATH}states.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "        df_cities = pd.read_csv(f\"{BASE_PATH}all_cities.csv\", low_memory=False)\n",
        "        df_cities_main = df_cities[['geonameid', 'name', 'country_code', 'admin1_code',\n",
        "                                    'is_capital', 'is_state_capital']].copy()\n",
        "        df_cities_main.rename(columns={'name': 'official_name'}, inplace=True)\n",
        "        df_cities_main.to_csv(f\"{BASE_PATH}cities_main.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "        df_cities_info = df_cities[['geonameid', 'latitude', 'longitude', 'population', 'timezone']].copy()\n",
        "        df_cities_info.to_csv(f\"{BASE_PATH}cities_info_main.csv\", index=False, encoding='utf-8')\n",
        "\n",
        "        print(\"Cambios finales realizados\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error realizando cambios finales: {e}\")\n",
        "\n",
        "\n",
        "    # Paso 7: Crear archivo comprimido\n",
        "    try:\n",
        "        print(\"Comprimiendo resultados...\")\n",
        "        !zip -r /content/geodata.zip {BASE_PATH}\n",
        "        print(\"Archivo comprimido creado en /content/geodata.zip\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error comprimiendo resultados: {e}\")\n",
        "\n",
        "    print(\"Proceso ETL completado!\")"
      ],
      "metadata": {
        "id": "gPUERksqEOw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2Zm9XUr-EcL5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}